{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f613103f",
   "metadata": {},
   "source": [
    "# Introduction to BART with dailymail"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8038c12d",
   "metadata": {},
   "source": [
    "## 1. Import libraries + cnn_dailymail dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e09c59c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/clementgillet/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline, set_seed\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "from datasets import load_dataset, load_metric\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa97ea01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset cnn_dailymail (/Users/clementgillet/.cache/huggingface/datasets/cnn_dailymail/default/3.0.0/1b3c71476f6d152c31c1730e83ccb08bcf23e348233f4fcc11e182248e6bf7de)\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0325930118560791,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 24,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 3,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96edf49b4d5043e4b4381438b42453d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features in cnn_dailymail : ['article', 'highlights', 'id']\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\"cnn_dailymail\", version=\"3.0.0\")\n",
    "\n",
    "print(f\"Features in cnn_dailymail : {dataset['train'].column_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26079a23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Article (excerpt of 500 characters, total length: 4051):\n",
      "\n",
      "Editor's note: In our Behind the Scenes series, CNN correspondents share their experiences in covering news and analyze the stories behind the events. Here, Soledad O'Brien takes users inside a jail where many of the inmates are mentally ill. An inmate housed on the \"forgotten floor,\" where many mentally ill inmates are housed in Miami before trial. MIAMI, Florida (CNN) -- The ninth floor of the Miami-Dade pretrial detention facility is dubbed the \"forgotten floor.\" Here, inmates with the most s\n",
      "\n",
      "Summary (length: 281):\n",
      "Mentally ill inmates in Miami are housed on the \"forgotten floor\"\n",
      "Judge Steven Leifman says most are there as a result of \"avoidable felonies\"\n",
      "While CNN tours facility, patient shouts: \"I am the son of the president\"\n",
      "Leifman says the system is unjust and he's fighting for change .\n"
     ]
    }
   ],
   "source": [
    "sample = dataset[\"train\"][1]\n",
    "print(f\"\"\"\n",
    "Article (excerpt of 500 characters, total length: {len(sample[\"article\"])}):\n",
    "\"\"\")\n",
    "print(sample[\"article\"][:500])\n",
    "print(f'\\nSummary (length: {len(sample[\"highlights\"])}):')\n",
    "print(sample[\"highlights\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ee3d1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text = dataset[\"train\"][1][\"article\"][:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f73bbbf",
   "metadata": {},
   "source": [
    "## 2. BART (fine-tuned on CNN Dailymail)\n",
    "\n",
    "**Denoising Autoencoder** to training Seq2Seq models by corrupting the text with an arbitrary noising function and then learning a model to reconstruct the original text. \n",
    "\n",
    "It uses a transformer with **Bidirectional encoder** (like BERT) and a **left-to-right decoder** (like GPT).<br/>\n",
    "This means that the **encoder attention mask is fully visible** and the **decoder attention mask is causal**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9462dd6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
    "pipe_out = pipe(sample_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63677bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = '\\n'.join(sent_tokenize(pipe_out[0]['summary_text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5777abe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground truth summary:\n",
      "\n",
      " Mentally ill inmates in Miami are housed on the \"forgotten floor\"\n",
      "Judge Steven Leifman says most are there as a result of \"avoidable felonies\"\n",
      "While CNN tours facility, patient shouts: \"I am the son of the president\"\n",
      "Leifman says the system is unjust and he's fighting for change . \n",
      "\n",
      "\n",
      "BART-generated summary :\n",
      "\n",
      " Miami-Dade pretrial detention facility is dubbed the \"forgotten floor\" Here, inmates with the most severe mental illnesses are incarcerated. Most often, they face drug charges or charges of assaulting an officer. Judge Steven Leifman says the arrests often result from confrontations with police.\n"
     ]
    }
   ],
   "source": [
    "print(\"Ground truth summary:\\n\\n\",sample[\"highlights\"],\"\\n\\n\")\n",
    "print(\"BART-generated summary :\\n\\n\",pipe_out[0][\"summary_text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e7bb0d",
   "metadata": {},
   "source": [
    "## 3. Evaluation (SacreBLEU & ROUGE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec04f2f",
   "metadata": {},
   "source": [
    "- **BLEU** measures **precision**. How much of the words (n-grams) from the machine-generated summary appear in the gold summary.\n",
    "\n",
    "- **ROUGE** measures **recall**. How much of the words (n-grams) from the gold summary appear in the machine-generated summary. <br/><br/> In summarization, high recall is more important than high precision.\n",
    "<br/><br/>\n",
    "- ROUGE-N $\\rightarrow$ Measures the match-rate of n-grams between the model output and the gold reference\n",
    "- ROUGE-L $\\rightarrow$ Measures the Longest Common Subsequence (LCS) between the model output and the gold reference. In other words, we count the longest sequence of tokens that is shared between both summarties.it calculates the score per sentence and averages it for the whole summary\n",
    "- ROUGE-Lsum $\\rightarrow$ In contrast, it calculates the LCS directly over the whole summary.\n",
    "\n",
    "(n-gram = a sequence of n tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d890fcf6",
   "metadata": {},
   "source": [
    "### a) BLEU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "934c7d67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k3/7lg5gqsd1_72l0df3dd6jwqw0000gn/T/ipykernel_18850/2824568306.py:1: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n",
      "  bleu_metric = load_metric(\"sacrebleu\")\n"
     ]
    }
   ],
   "source": [
    "bleu_metric = load_metric(\"sacrebleu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "692e152a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "BLEU results on BART-large-cnn:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>score</th>\n",
       "      <td>10.887081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>counts</th>\n",
       "      <td>[19, 7, 5, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>totals</th>\n",
       "      <td>[55, 54, 53, 52]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precisions</th>\n",
       "      <td>[34.54545454545455, 12.962962962962964, 9.4339...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bp</th>\n",
       "      <td>0.96429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sys_len</th>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ref_len</th>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>[34.55, 12.96, 9.43, 3.85]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        Value\n",
       "score                                               10.887081\n",
       "counts                                          [19, 7, 5, 2]\n",
       "totals                                       [55, 54, 53, 52]\n",
       "precisions  [34.54545454545455, 12.962962962962964, 9.4339...\n",
       "bp                                                    0.96429\n",
       "sys_len                                                    55\n",
       "ref_len                                                    57\n",
       "precision                          [34.55, 12.96, 9.43, 3.85]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bleu_metric.add(prediction = [summary], reference = [sample[\"highlights\"]] )\n",
    "\n",
    "results = bleu_metric.compute(smooth_method = 'floor', smooth_value = 0 )\n",
    "\n",
    "results['precision'] = [np.round(p, 2) for p in results['precisions'] ]\n",
    "print(\"\\n\\nBLEU results on BART-large-cnn:\")\n",
    "pd.DataFrame.from_dict(results, orient = 'index', columns = ['Value'] )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1330bc6",
   "metadata": {},
   "source": [
    "### b) ROUGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f1a54e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge_metric = load_metric(\"rouge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7f98111d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score(precision=0.20454545454545456, recall=0.1836734693877551, fmeasure=0.1935483870967742)\n",
      "\n",
      "\n",
      "ROUGE results on BART-large-cnn:\n",
      "{'rouge1': 0.3655913978494624, 'rouge2': 0.13186813186813184, 'rougeL': 0.1935483870967742, 'rougeLsum': 0.1935483870967742}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rouge1</th>\n",
       "      <th>rouge2</th>\n",
       "      <th>rougeL</th>\n",
       "      <th>rougeLsum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.365591</td>\n",
       "      <td>0.131868</td>\n",
       "      <td>0.193548</td>\n",
       "      <td>0.193548</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     rouge1    rouge2    rougeL  rougeLsum\n",
       "0  0.365591  0.131868  0.193548   0.193548"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rouge_names = [\"rouge1\", \"rouge2\", \"rougeL\", \"rougeLsum\"]\n",
    "\n",
    "rouge_metric.add(prediction = [summary], reference = [sample[\"highlights\"]] )\n",
    "score = rouge_metric.compute()\n",
    "rouge_dict =  dict((rn, score[rn].mid.fmeasure) for rn in rouge_names )\n",
    "print(score[\"rougeL\"].mid)\n",
    "print(\"\\n\\nROUGE results on BART-large-cnn:\")\n",
    "print(rouge_dict)\n",
    "pd.DataFrame.from_dict([rouge_dict])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554bd8d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
