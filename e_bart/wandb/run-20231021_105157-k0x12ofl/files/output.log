WARNING:datasets.builder:Found cached dataset json (/Users/clementgillet/.cache/huggingface/datasets/json/default-bc7c43bbf08c9cab/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96)
100%|██████████| 3/3 [00:00<00:00, 122.62it/s]
WARNING:datasets.builder:Found cached dataset json (/Users/clementgillet/.cache/huggingface/datasets/json/default-f55bc7ce5c066cdf/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96)
100%|██████████| 3/3 [00:00<00:00, 84.31it/s]
INFO:model.modeling_utils:loading weights file /Users/clementgillet/Desktop/Master_Hub/ebart.large/model.bin
INFO:model.modeling_utils:All model checkpoint weights were used when initializing BartForConditionalGeneration.
WARNING:model.modeling_utils:Some weights of BartForConditionalGeneration were not initialized from the model checkpoint at /Users/clementgillet/Desktop/Master_Hub/ebart.large/model.bin and are newly initialized: ['model.decoder.layers.9.g_encoder_attn.q_proj.bias', 'model.decoder.layers.1.g_encoder_attn.out_proj.bias', 'model.decoder.layers.10.g_encoder_attn.v_proj.bias', 'model.decoder.layers.8.g_encoder_attn.q_proj.bias', 'model.decoder.layers.8.g_encoder_attn.v_proj.bias', 'model.decoder.layers.1.g_encoder_attn.v_proj.weight', 'model.decoder.layers.10.g_encoder_attn.out_proj.bias', 'model.decoder.layers.7.g_encoder_attn.v_proj.bias', 'model.decoder.layers.5.g_encoder_attn.k_proj.weight', 'model.decoder.layers.10.g_encoder_attn.q_proj.bias', 'model.decoder.layers.4.g_encoder_attn.q_proj.weight', 'model.decoder.layers.1.g_encoder_attn.k_proj.bias', 'model.decoder.layers.10.g_encoder_attn.k_proj.weight', 'model.decoder.layers.0.g_encoder_attn.v_proj.weight', 'model.decoder.layers.7.g_encoder_attn.q_proj.weight', 'model.decoder.layers.9.g_encoder_attn.k_proj.weight', 'model.decoder.layers.10.g_encoder_attn.k_proj.bias', 'model.decoder.layers.4.g_encoder_attn.k_proj.weight', 'model.decoder.layers.2.g_encoder_attn.v_proj.bias', 'model.decoder.layers.1.g_encoder_attn.out_proj.weight', 'model.decoder.layers.8.g_encoder_attn.out_proj.weight', 'model.decoder.layers.3.g_encoder_attn.v_proj.weight', 'model.decoder.layers.0.g_encoder_attn.q_proj.bias', 'model.decoder.layers.5.g_encoder_attn.v_proj.weight', 'model.decoder.layers.3.g_encoder_attn.k_proj.bias', 'model.decoder.layers.0.g_encoder_attn.v_proj.bias', 'model.decoder.layers.5.g_encoder_attn.out_proj.bias', 'model.decoder.layers.11.g_encoder_attn.out_proj.bias', 'model.decoder.layers.11.g_encoder_attn.k_proj.bias', 'model.decoder.layers.3.g_encoder_attn.out_proj.bias', 'model.decoder.layers.6.g_encoder_attn.v_proj.weight', 'model.decoder.layers.6.g_encoder_attn.v_proj.bias', 'model.decoder.layers.10.g_encoder_attn.out_proj.weight', 'model.decoder.layers.11.g_encoder_attn.q_proj.bias', 'model.decoder.layers.2.g_encoder_attn.k_proj.weight', 'model.decoder.layers.0.g_encoder_attn.out_proj.weight', 'model.decoder.layers.4.g_encoder_attn.v_proj.bias', 'model.decoder.layers.6.g_encoder_attn.k_proj.weight', 'model.decoder.layers.7.g_encoder_attn.out_proj.weight', 'model.decoder.layers.8.g_encoder_attn.k_proj.weight', 'model.decoder.layers.2.g_encoder_attn.k_proj.bias', 'model.decoder.layers.2.g_encoder_attn.q_proj.bias', 'model.decoder.layers.1.g_encoder_attn.q_proj.bias', 'model.decoder.layers.11.g_encoder_attn.v_proj.bias', 'model.decoder.layers.3.g_encoder_attn.q_proj.bias', 'model.decoder.layers.5.g_encoder_attn.out_proj.weight', 'model.decoder.layers.11.g_encoder_attn.v_proj.weight', 'model.decoder.layers.3.g_encoder_attn.out_proj.weight', 'model.decoder.layers.4.g_encoder_attn.out_proj.bias', 'model.decoder.layers.8.g_encoder_attn.q_proj.weight', 'model.decoder.layers.11.g_encoder_attn.out_proj.weight', 'model.decoder.layers.1.g_encoder_attn.v_proj.bias', 'model.decoder.layers.9.g_encoder_attn.v_proj.weight', 'model.decoder.layers.5.g_encoder_attn.v_proj.bias', 'model.decoder.layers.3.g_encoder_attn.v_proj.bias', 'model.decoder.layers.11.g_encoder_attn.q_proj.weight', 'model.decoder.layers.10.g_encoder_attn.v_proj.weight', 'model.decoder.layers.7.g_encoder_attn.out_proj.bias', 'model.decoder.layers.4.g_encoder_attn.q_proj.bias', 'model.decoder.layers.5.g_encoder_attn.q_proj.bias', 'model.decoder.layers.11.g_encoder_attn.k_proj.weight', 'model.decoder.layers.4.g_encoder_attn.out_proj.weight', 'model.decoder.layers.1.g_encoder_attn.q_proj.weight', 'model.decoder.layers.0.g_encoder_attn.k_proj.weight', 'model.decoder.layers.0.g_encoder_attn.k_proj.bias', 'model.decoder.layers.4.g_encoder_attn.k_proj.bias', 'model.decoder.layers.6.g_encoder_attn.out_proj.bias', 'model.decoder.layers.2.g_encoder_attn.v_proj.weight', 'model.decoder.layers.6.g_encoder_attn.q_proj.bias', 'model.decoder.layers.9.g_encoder_attn.k_proj.bias', 'model.decoder.layers.0.g_encoder_attn.q_proj.weight', 'model.decoder.layers.2.g_encoder_attn.out_proj.weight', 'model.decoder.layers.7.g_encoder_attn.v_proj.weight', 'model.decoder.layers.6.g_encoder_attn.q_proj.weight', 'model.decoder.layers.7.g_encoder_attn.q_proj.bias', 'model.decoder.layers.9.g_encoder_attn.q_proj.weight', 'model.decoder.layers.7.g_encoder_attn.k_proj.weight', 'model.decoder.layers.9.g_encoder_attn.out_proj.weight', 'model.decoder.layers.4.g_encoder_attn.v_proj.weight', 'model.decoder.layers.7.g_encoder_attn.k_proj.bias', 'model.decoder.layers.3.g_encoder_attn.k_proj.weight', 'model.decoder.layers.3.g_encoder_attn.q_proj.weight', 'model.decoder.layers.6.g_encoder_attn.out_proj.weight', 'model.decoder.layers.9.g_encoder_attn.out_proj.bias', 'model.decoder.layers.8.g_encoder_attn.k_proj.bias', 'model.decoder.layers.6.g_encoder_attn.k_proj.bias', 'model.decoder.layers.1.g_encoder_attn.k_proj.weight', 'model.decoder.layers.2.g_encoder_attn.out_proj.bias', 'model.decoder.layers.9.g_encoder_attn.v_proj.bias', 'model.decoder.layers.5.g_encoder_attn.k_proj.bias', 'model.decoder.layers.5.g_encoder_attn.q_proj.weight', 'model.decoder.layers.8.g_encoder_attn.out_proj.bias', 'model.decoder.layers.10.g_encoder_attn.q_proj.weight', 'model.decoder.layers.0.g_encoder_attn.out_proj.bias', 'model.decoder.layers.2.g_encoder_attn.q_proj.weight', 'model.decoder.layers.8.g_encoder_attn.v_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
INFO:model.modeling_utils:Generation config file not found, using a generation config created from the model config.
WARNING:datasets.arrow_dataset:Loading cached processed dataset at /Users/clementgillet/.cache/huggingface/datasets/json/default-bc7c43bbf08c9cab/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-65529769661a3995.arrow
WARNING:datasets.arrow_dataset:Loading cached processed dataset at /Users/clementgillet/.cache/huggingface/datasets/json/default-bc7c43bbf08c9cab/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-3014a693b9ea7030.arrow
/Users/clementgillet/PycharmProjects/E-BART/e_bart/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
INFO:trainer:***** Running training *****
INFO:trainer:  Num examples = 2
INFO:trainer:  Num Epochs = 5
INFO:trainer:  Instantaneous batch size per device = 4
INFO:trainer:  Total train batch size (w. parallel, distributed & accumulation) = 4
INFO:trainer:  Gradient Accumulation steps = 1
INFO:trainer:  Total optimization steps = 5
INFO:trainer:  Number of trainable parameters = 608,879,616
------------------------------------------------------------------------------
TRAIN INPUTS :  {'input_ids': tensor([[    0,   113, 40866,  ...,    13,     5,     2],
        [    0, 28512, 16123,  ...,     1,     1,     1]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([[    0,   113, 40866, 41902,  6822, 13287, 35865,   113,    16,    10,
           291,    12,  7755,  3748,   651,    13, 24098,  4455,    14,  2075,
           804,    31,  1824,    12, 14517, 14539,     5, 24098,  1012,   930,
         24827,     6,    22, 40866, 41902,    35,  3920,  6830, 23987,    72,
          4028, 13287, 35865,  3748, 48663,  1165,    41,  1194,    19,    10,
          3250,     6,  9613,    50,  1971,  2704,   484,  4388,   819,  3424,
             4,    85,    67,  8785,   122,    15,    10,  8479, 12667,  3400,
          1864,   725,  4037,  5331,     4, 21270,  7618,    30,    20,  7765,
         12749,  8220,     6,   764,  2659,     4,     2,  -100,  -100,  -100,
          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
          -100,  -100,  -100,  -100,  -100,  -100,  -100],
        [    0, 16215,  8365, 16704, 17700,     8,    39,  4025,    32,  4568,
            13,   277,   334,    76,  5307,    23,    10, 20915,  4281,  8725,
           343,   239,   334,    11,  2201,     4,    20,  2948,  1067,     7,
           349,    97,    59,    49, 12429,   521,     6,   258,     5,   205,
             8,     5,  1099,     4,    20,  2948, 14332,   236,     7,  9769,
            49,   521,     6,    53,   349,  3254,    16,    41,  1736,    54,
            40,   109,   383,    11,    39,    50,    69,   308,   169,     7,
          3042,     5,   775,    51,  4724,     4,   252,    67,    33, 28900,
         33498,    15,     5,   521,  1235,     6,     8,   141,   275,     7,
          8249,     8,  8882,   106,     4,    20,   942,     9,     5,   334,
          5741,     7,    28,    25,  2105,    25,   678,     6,    61,  1171,
           519,  1294,  4844,  2662,    15,     5,  1294, 10437,  1540,     4,
         17700,    18,  1380,    42,    76,     9, 31925,     8, 23843,    76,
         36504,    16,   117,   430,    87,   986,   107,     6,  1712,     5,
          2523,     8,  2419,    33,  1714,     4, 17700,  5741,     7,   120,
           149,     7,    39,   521,     6,  2128,    19,  1282,     8,  2128,
          5203,    11, 18672,  2988,     4,  1648, 17700,    34,    39,  3433,
           477,     6,    61,   189,   898,    11,   123,   608,   383,    37,
            74,  1153,  8109,     7,  1003,    32,  1593,     4,   125,    71,
            70,    16,    26,     8,   626,     6,    89,    16,   220,    76,
             8,   277,   333,     9,   521,     4,     2]]), 'g': tensor([[    0,   113, 40866,  ...,    13,     5,     2],
        [    0, 28512, 16123,  ...,     1,     1,     1]]), 'decoder_input_ids': tensor([[    2,     0,   113, 40866, 41902,  6822, 13287, 35865,   113,    16,
            10,   291,    12,  7755,  3748,   651,    13, 24098,  4455,    14,
          2075,   804,    31,  1824,    12, 14517, 14539,     5, 24098,  1012,
           930, 24827,     6,    22, 40866, 41902,    35,  3920,  6830, 23987,
            72,  4028, 13287, 35865,  3748, 48663,  1165,    41,  1194,    19,
            10,  3250,     6,  9613,    50,  1971,  2704,   484,  4388,   819,
          3424,     4,    85,    67,  8785,   122,    15,    10,  8479, 12667,
          3400,  1864,   725,  4037,  5331,     4, 21270,  7618,    30,    20,
          7765, 12749,  8220,     6,   764,  2659,     4,     2,     1,     1,
             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,
             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,
             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,
             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,
             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,
             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,
             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,
             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,
             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,
             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,
             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,
             1,     1,     1,     1,     1,     1,     1],
        [    2,     0, 16215,  8365, 16704, 17700,     8,    39,  4025,    32,
          4568,    13,   277,   334,    76,  5307,    23,    10, 20915,  4281,
          8725,   343,   239,   334,    11,  2201,     4,    20,  2948,  1067,
             7,   349,    97,    59,    49, 12429,   521,     6,   258,     5,
           205,     8,     5,  1099,     4,    20,  2948, 14332,   236,     7,
          9769,    49,   521,     6,    53,   349,  3254,    16,    41,  1736,
            54,    40,   109,   383,    11,    39,    50,    69,   308,   169,
             7,  3042,     5,   775,    51,  4724,     4,   252,    67,    33,
         28900, 33498,    15,     5,   521,  1235,     6,     8,   141,   275,
             7,  8249,     8,  8882,   106,     4,    20,   942,     9,     5,
           334,  5741,     7,    28,    25,  2105,    25,   678,     6,    61,
          1171,   519,  1294,  4844,  2662,    15,     5,  1294, 10437,  1540,
             4, 17700,    18,  1380,    42,    76,     9, 31925,     8, 23843,
            76, 36504,    16,   117,   430,    87,   986,   107,     6,  1712,
             5,  2523,     8,  2419,    33,  1714,     4, 17700,  5741,     7,
           120,   149,     7,    39,   521,     6,  2128,    19,  1282,     8,
          2128,  5203,    11, 18672,  2988,     4,  1648, 17700,    34,    39,
          3433,   477,     6,    61,   189,   898,    11,   123,   608,   383,
            37,    74,  1153,  8109,     7,  1003,    32,  1593,     4,   125,
            71,    70,    16,    26,     8,   626,     6,    89,    16,   220,
            76,     8,   277,   333,     9,   521,     4]])}
------------------------------------------------------------------------------
  0%|          | 0/5 [00:00<?, ?it/s]You're using a BartTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
---------------------------------------------------------------------
TRAIN X-HIDDEN OUT :  BaseModelOutput(last_hidden_state=tensor([[[ 0.0029,  0.0466,  0.0241,  ...,  0.0040, -0.0009,  0.0042],
         [ 0.0411,  0.2266, -0.3788,  ..., -0.1591, -0.1201, -0.1515],
         [-0.0753, -0.0920,  0.0401,  ..., -0.1883, -0.0638,  0.1088],
         ...,
         [-0.1585,  0.4778,  0.0478,  ...,  0.1142, -0.1948, -0.2410],
         [ 0.4990,  0.1309, -0.0756,  ...,  0.1941, -0.0396,  0.1294],
         [ 0.0233,  0.5075, -0.1227,  ...,  0.2180,  0.0169, -0.1456]],
        [[ 0.0006,  0.0469,  0.0403,  ...,  0.0100,  0.0158, -0.0043],
         [-0.0580, -0.0588, -0.3303,  ..., -0.1318, -0.0691,  0.0873],
         [-0.1027,  0.0327, -0.1646,  ...,  0.0510, -0.0181,  0.0287],
         ...,
         [ 0.2474,  0.1774,  0.0041,  ...,  0.1810, -0.0988,  0.0749],
         [ 0.0613,  0.4878,  0.0697,  ...,  0.2797, -0.0262, -0.0910],
         [ 0.0067,  0.0410,  0.0450,  ..., -0.0014,  0.0181,  0.0049]]],
       grad_fn=<NativeLayerNormBackward0>), hidden_states=None, attentions=None)
TRAIN G-HIDDEN OUT :  BaseModelOutput(last_hidden_state=tensor([[[ 0.0029,  0.0436,  0.0216,  ...,  0.0035,  0.0059,  0.0012],
         [-0.0320,  0.0604, -0.3925,  ..., -0.2646, -0.1134, -0.0595],
         [-0.0209, -0.3095,  0.0333,  ..., -0.1202, -0.0178, -0.0560],
         ...,
         [-0.0625,  0.3340,  0.2959,  ...,  0.0638,  0.0045, -0.3655],
         [ 0.2833, -0.1439,  0.0441,  ...,  0.2481, -0.1761,  0.1986],
         [-0.0381,  0.5991, -0.2123,  ...,  0.2404, -0.0276, -0.0811]],
        [[ 0.0055,  0.0421,  0.0276,  ...,  0.0034, -0.0191,  0.0107],
         [-0.0603, -0.0153, -0.3052,  ..., -0.1260, -0.0921,  0.0439],
         [-0.1280,  0.0216, -0.0023,  ...,  0.0502, -0.0573,  0.0488],
         ...,
         [-0.0104,  0.0429,  0.0210,  ...,  0.0051, -0.0151,  0.0129],
         [ 0.0026,  0.0500,  0.0089,  ...,  0.0074, -0.0138,  0.0064],
         [ 0.0074,  0.2792,  0.1425,  ...,  0.2609, -0.1506,  0.0061]]],
       grad_fn=<NativeLayerNormBackward0>), hidden_states=None, attentions=None)
Y_in :  tensor([[    2,     0,   113, 40866, 41902,  6822, 13287, 35865,   113,    16,
            10,   291,    12,  7755,  3748,   651,    13, 24098,  4455,    14,
          2075,   804,    31,  1824,    12, 14517, 14539,     5, 24098,  1012,
           930, 24827,     6,    22, 40866, 41902,    35,  3920,  6830, 23987,
            72,  4028, 13287, 35865,  3748, 48663,  1165,    41,  1194,    19,
            10,  3250,     6,  9613,    50,  1971,  2704,   484,  4388,   819,
          3424,     4,    85,    67,  8785,   122,    15,    10,  8479, 12667,
          3400,  1864,   725,  4037,  5331,     4, 21270,  7618,    30,    20,
          7765, 12749,  8220,     6,   764,  2659,     4,     2,     1,     1,
             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,
             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,
             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,
             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,
             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,
             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,
             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,
             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,
             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,
             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,
             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,
             1,     1,     1,     1,     1,     1,     1],
        [    2,     0, 16215,  8365, 16704, 17700,     8,    39,  4025,    32,
          4568,    13,   277,   334,    76,  5307,    23,    10, 20915,  4281,
          8725,   343,   239,   334,    11,  2201,     4,    20,  2948,  1067,
             7,   349,    97,    59,    49, 12429,   521,     6,   258,     5,
           205,     8,     5,  1099,     4,    20,  2948, 14332,   236,     7,
          9769,    49,   521,     6,    53,   349,  3254,    16,    41,  1736,
            54,    40,   109,   383,    11,    39,    50,    69,   308,   169,
             7,  3042,     5,   775,    51,  4724,     4,   252,    67,    33,
         28900, 33498,    15,     5,   521,  1235,     6,     8,   141,   275,
             7,  8249,     8,  8882,   106,     4,    20,   942,     9,     5,
           334,  5741,     7,    28,    25,  2105,    25,   678,     6,    61,
          1171,   519,  1294,  4844,  2662,    15,     5,  1294, 10437,  1540,
             4, 17700,    18,  1380,    42,    76,     9, 31925,     8, 23843,
            76, 36504,    16,   117,   430,    87,   986,   107,     6,  1712,
             5,  2523,     8,  2419,    33,  1714,     4, 17700,  5741,     7,
           120,   149,     7,    39,   521,     6,  2128,    19,  1282,     8,
          2128,  5203,    11, 18672,  2988,     4,  1648, 17700,    34,    39,
          3433,   477,     6,    61,   189,   898,    11,   123,   608,   383,
            37,    74,  1153,  8109,     7,  1003,    32,  1593,     4,   125,
            71,    70,    16,    26,     8,   626,     6,    89,    16,   220,
            76,     8,   277,   333,     9,   521,     4]])
---------------------------------------------------------------------
---------------------------------------------------------------------
TRAIN X-HIDDEN IN_DEC :  tensor([[[ 0.0029,  0.0466,  0.0241,  ...,  0.0040, -0.0009,  0.0042],
         [ 0.0411,  0.2266, -0.3788,  ..., -0.1591, -0.1201, -0.1515],
         [-0.0753, -0.0920,  0.0401,  ..., -0.1883, -0.0638,  0.1088],
         ...,
         [-0.1585,  0.4778,  0.0478,  ...,  0.1142, -0.1948, -0.2410],
         [ 0.4990,  0.1309, -0.0756,  ...,  0.1941, -0.0396,  0.1294],
         [ 0.0233,  0.5075, -0.1227,  ...,  0.2180,  0.0169, -0.1456]],
        [[ 0.0006,  0.0469,  0.0403,  ...,  0.0100,  0.0158, -0.0043],
         [-0.0580, -0.0588, -0.3303,  ..., -0.1318, -0.0691,  0.0873],
         [-0.1027,  0.0327, -0.1646,  ...,  0.0510, -0.0181,  0.0287],
         ...,
         [ 0.2474,  0.1774,  0.0041,  ...,  0.1810, -0.0988,  0.0749],
         [ 0.0613,  0.4878,  0.0697,  ...,  0.2797, -0.0262, -0.0910],
         [ 0.0067,  0.0410,  0.0450,  ..., -0.0014,  0.0181,  0.0049]]],
       grad_fn=<NativeLayerNormBackward0>)
TRAIN G-HIDDEN IN_DEC :  tensor([[[ 0.0029,  0.0436,  0.0216,  ...,  0.0035,  0.0059,  0.0012],
         [-0.0320,  0.0604, -0.3925,  ..., -0.2646, -0.1134, -0.0595],
         [-0.0209, -0.3095,  0.0333,  ..., -0.1202, -0.0178, -0.0560],
         ...,
         [-0.0625,  0.3340,  0.2959,  ...,  0.0638,  0.0045, -0.3655],
         [ 0.2833, -0.1439,  0.0441,  ...,  0.2481, -0.1761,  0.1986],
         [-0.0381,  0.5991, -0.2123,  ...,  0.2404, -0.0276, -0.0811]],
        [[ 0.0055,  0.0421,  0.0276,  ...,  0.0034, -0.0191,  0.0107],
         [-0.0603, -0.0153, -0.3052,  ..., -0.1260, -0.0921,  0.0439],
         [-0.1280,  0.0216, -0.0023,  ...,  0.0502, -0.0573,  0.0488],
         ...,
         [-0.0104,  0.0429,  0.0210,  ...,  0.0051, -0.0151,  0.0129],
         [ 0.0026,  0.0500,  0.0089,  ...,  0.0074, -0.0138,  0.0064],
         [ 0.0074,  0.2792,  0.1425,  ...,  0.2609, -0.1506,  0.0061]]],
       grad_fn=<NativeLayerNormBackward0>)
---------------------------------------------------------------------
---------------------------------------------------------------------
TRAIN X-HIDDEN IN_DEC :  tensor([[[ 0.0029,  0.0466,  0.0241,  ...,  0.0040, -0.0009,  0.0042],
         [ 0.0411,  0.2266, -0.3788,  ..., -0.1591, -0.1201, -0.1515],
         [-0.0753, -0.0920,  0.0401,  ..., -0.1883, -0.0638,  0.1088],
         ...,
         [-0.1585,  0.4778,  0.0478,  ...,  0.1142, -0.1948, -0.2410],
         [ 0.4990,  0.1309, -0.0756,  ...,  0.1941, -0.0396,  0.1294],
         [ 0.0233,  0.5075, -0.1227,  ...,  0.2180,  0.0169, -0.1456]],
        [[ 0.0006,  0.0469,  0.0403,  ...,  0.0100,  0.0158, -0.0043],
         [-0.0580, -0.0588, -0.3303,  ..., -0.1318, -0.0691,  0.0873],
         [-0.1027,  0.0327, -0.1646,  ...,  0.0510, -0.0181,  0.0287],
         ...,
         [ 0.2474,  0.1774,  0.0041,  ...,  0.1810, -0.0988,  0.0749],
         [ 0.0613,  0.4878,  0.0697,  ...,  0.2797, -0.0262, -0.0910],
         [ 0.0067,  0.0410,  0.0450,  ..., -0.0014,  0.0181,  0.0049]]],
       grad_fn=<NativeLayerNormBackward0>)
TRAIN G-HIDDEN IN_DEC :  tensor([[[ 0.0029,  0.0436,  0.0216,  ...,  0.0035,  0.0059,  0.0012],
         [-0.0320,  0.0604, -0.3925,  ..., -0.2646, -0.1134, -0.0595],
         [-0.0209, -0.3095,  0.0333,  ..., -0.1202, -0.0178, -0.0560],
         ...,
         [-0.0625,  0.3340,  0.2959,  ...,  0.0638,  0.0045, -0.3655],
         [ 0.2833, -0.1439,  0.0441,  ...,  0.2481, -0.1761,  0.1986],
         [-0.0381,  0.5991, -0.2123,  ...,  0.2404, -0.0276, -0.0811]],
        [[ 0.0055,  0.0421,  0.0276,  ...,  0.0034, -0.0191,  0.0107],
         [-0.0603, -0.0153, -0.3052,  ..., -0.1260, -0.0921,  0.0439],
         [-0.1280,  0.0216, -0.0023,  ...,  0.0502, -0.0573,  0.0488],
         ...,
         [-0.0104,  0.0429,  0.0210,  ...,  0.0051, -0.0151,  0.0129],
         [ 0.0026,  0.0500,  0.0089,  ...,  0.0074, -0.0138,  0.0064],
         [ 0.0074,  0.2792,  0.1425,  ...,  0.2609, -0.1506,  0.0061]]],
       grad_fn=<NativeLayerNormBackward0>)
---------------------------------------------------------------------
---------------------------------------------------------------------
TRAIN X-HIDDEN IN_DEC :  tensor([[[ 0.0029,  0.0466,  0.0241,  ...,  0.0040, -0.0009,  0.0042],
         [ 0.0411,  0.2266, -0.3788,  ..., -0.1591, -0.1201, -0.1515],
         [-0.0753, -0.0920,  0.0401,  ..., -0.1883, -0.0638,  0.1088],
         ...,
         [-0.1585,  0.4778,  0.0478,  ...,  0.1142, -0.1948, -0.2410],
         [ 0.4990,  0.1309, -0.0756,  ...,  0.1941, -0.0396,  0.1294],
         [ 0.0233,  0.5075, -0.1227,  ...,  0.2180,  0.0169, -0.1456]],
        [[ 0.0006,  0.0469,  0.0403,  ...,  0.0100,  0.0158, -0.0043],
         [-0.0580, -0.0588, -0.3303,  ..., -0.1318, -0.0691,  0.0873],
         [-0.1027,  0.0327, -0.1646,  ...,  0.0510, -0.0181,  0.0287],
         ...,
         [ 0.2474,  0.1774,  0.0041,  ...,  0.1810, -0.0988,  0.0749],
         [ 0.0613,  0.4878,  0.0697,  ...,  0.2797, -0.0262, -0.0910],
         [ 0.0067,  0.0410,  0.0450,  ..., -0.0014,  0.0181,  0.0049]]],
       grad_fn=<NativeLayerNormBackward0>)
TRAIN G-HIDDEN IN_DEC :  tensor([[[ 0.0029,  0.0436,  0.0216,  ...,  0.0035,  0.0059,  0.0012],
         [-0.0320,  0.0604, -0.3925,  ..., -0.2646, -0.1134, -0.0595],
         [-0.0209, -0.3095,  0.0333,  ..., -0.1202, -0.0178, -0.0560],
         ...,
         [-0.0625,  0.3340,  0.2959,  ...,  0.0638,  0.0045, -0.3655],
         [ 0.2833, -0.1439,  0.0441,  ...,  0.2481, -0.1761,  0.1986],
         [-0.0381,  0.5991, -0.2123,  ...,  0.2404, -0.0276, -0.0811]],
        [[ 0.0055,  0.0421,  0.0276,  ...,  0.0034, -0.0191,  0.0107],
         [-0.0603, -0.0153, -0.3052,  ..., -0.1260, -0.0921,  0.0439],
         [-0.1280,  0.0216, -0.0023,  ...,  0.0502, -0.0573,  0.0488],
         ...,
         [-0.0104,  0.0429,  0.0210,  ...,  0.0051, -0.0151,  0.0129],
         [ 0.0026,  0.0500,  0.0089,  ...,  0.0074, -0.0138,  0.0064],
         [ 0.0074,  0.2792,  0.1425,  ...,  0.2609, -0.1506,  0.0061]]],
       grad_fn=<NativeLayerNormBackward0>)
---------------------------------------------------------------------
---------------------------------------------------------------------
TRAIN X-HIDDEN IN_DEC :  tensor([[[ 0.0029,  0.0466,  0.0241,  ...,  0.0040, -0.0009,  0.0042],
         [ 0.0411,  0.2266, -0.3788,  ..., -0.1591, -0.1201, -0.1515],
         [-0.0753, -0.0920,  0.0401,  ..., -0.1883, -0.0638,  0.1088],
         ...,
         [-0.1585,  0.4778,  0.0478,  ...,  0.1142, -0.1948, -0.2410],
         [ 0.4990,  0.1309, -0.0756,  ...,  0.1941, -0.0396,  0.1294],
         [ 0.0233,  0.5075, -0.1227,  ...,  0.2180,  0.0169, -0.1456]],
        [[ 0.0006,  0.0469,  0.0403,  ...,  0.0100,  0.0158, -0.0043],
         [-0.0580, -0.0588, -0.3303,  ..., -0.1318, -0.0691,  0.0873],
         [-0.1027,  0.0327, -0.1646,  ...,  0.0510, -0.0181,  0.0287],
         ...,
         [ 0.2474,  0.1774,  0.0041,  ...,  0.1810, -0.0988,  0.0749],
         [ 0.0613,  0.4878,  0.0697,  ...,  0.2797, -0.0262, -0.0910],
         [ 0.0067,  0.0410,  0.0450,  ..., -0.0014,  0.0181,  0.0049]]],
       grad_fn=<NativeLayerNormBackward0>)
TRAIN G-HIDDEN IN_DEC :  tensor([[[ 0.0029,  0.0436,  0.0216,  ...,  0.0035,  0.0059,  0.0012],
         [-0.0320,  0.0604, -0.3925,  ..., -0.2646, -0.1134, -0.0595],
         [-0.0209, -0.3095,  0.0333,  ..., -0.1202, -0.0178, -0.0560],
         ...,
         [-0.0625,  0.3340,  0.2959,  ...,  0.0638,  0.0045, -0.3655],
         [ 0.2833, -0.1439,  0.0441,  ...,  0.2481, -0.1761,  0.1986],
         [-0.0381,  0.5991, -0.2123,  ...,  0.2404, -0.0276, -0.0811]],
        [[ 0.0055,  0.0421,  0.0276,  ...,  0.0034, -0.0191,  0.0107],
         [-0.0603, -0.0153, -0.3052,  ..., -0.1260, -0.0921,  0.0439],
         [-0.1280,  0.0216, -0.0023,  ...,  0.0502, -0.0573,  0.0488],
         ...,
         [-0.0104,  0.0429,  0.0210,  ...,  0.0051, -0.0151,  0.0129],
         [ 0.0026,  0.0500,  0.0089,  ...,  0.0074, -0.0138,  0.0064],
         [ 0.0074,  0.2792,  0.1425,  ...,  0.2609, -0.1506,  0.0061]]],
       grad_fn=<NativeLayerNormBackward0>)
---------------------------------------------------------------------
---------------------------------------------------------------------
TRAIN X-HIDDEN IN_DEC :  tensor([[[ 0.0029,  0.0466,  0.0241,  ...,  0.0040, -0.0009,  0.0042],
         [ 0.0411,  0.2266, -0.3788,  ..., -0.1591, -0.1201, -0.1515],
         [-0.0753, -0.0920,  0.0401,  ..., -0.1883, -0.0638,  0.1088],
         ...,
         [-0.1585,  0.4778,  0.0478,  ...,  0.1142, -0.1948, -0.2410],
         [ 0.4990,  0.1309, -0.0756,  ...,  0.1941, -0.0396,  0.1294],
         [ 0.0233,  0.5075, -0.1227,  ...,  0.2180,  0.0169, -0.1456]],
        [[ 0.0006,  0.0469,  0.0403,  ...,  0.0100,  0.0158, -0.0043],
         [-0.0580, -0.0588, -0.3303,  ..., -0.1318, -0.0691,  0.0873],
         [-0.1027,  0.0327, -0.1646,  ...,  0.0510, -0.0181,  0.0287],
         ...,
         [ 0.2474,  0.1774,  0.0041,  ...,  0.1810, -0.0988,  0.0749],
         [ 0.0613,  0.4878,  0.0697,  ...,  0.2797, -0.0262, -0.0910],
         [ 0.0067,  0.0410,  0.0450,  ..., -0.0014,  0.0181,  0.0049]]],
       grad_fn=<NativeLayerNormBackward0>)
TRAIN G-HIDDEN IN_DEC :  tensor([[[ 0.0029,  0.0436,  0.0216,  ...,  0.0035,  0.0059,  0.0012],
         [-0.0320,  0.0604, -0.3925,  ..., -0.2646, -0.1134, -0.0595],
         [-0.0209, -0.3095,  0.0333,  ..., -0.1202, -0.0178, -0.0560],
         ...,
         [-0.0625,  0.3340,  0.2959,  ...,  0.0638,  0.0045, -0.3655],
         [ 0.2833, -0.1439,  0.0441,  ...,  0.2481, -0.1761,  0.1986],
         [-0.0381,  0.5991, -0.2123,  ...,  0.2404, -0.0276, -0.0811]],
        [[ 0.0055,  0.0421,  0.0276,  ...,  0.0034, -0.0191,  0.0107],
         [-0.0603, -0.0153, -0.3052,  ..., -0.1260, -0.0921,  0.0439],
         [-0.1280,  0.0216, -0.0023,  ...,  0.0502, -0.0573,  0.0488],
         ...,
         [-0.0104,  0.0429,  0.0210,  ...,  0.0051, -0.0151,  0.0129],
         [ 0.0026,  0.0500,  0.0089,  ...,  0.0074, -0.0138,  0.0064],
         [ 0.0074,  0.2792,  0.1425,  ...,  0.2609, -0.1506,  0.0061]]],
       grad_fn=<NativeLayerNormBackward0>)
---------------------------------------------------------------------
---------------------------------------------------------------------
TRAIN X-HIDDEN IN_DEC :  tensor([[[ 0.0029,  0.0466,  0.0241,  ...,  0.0040, -0.0009,  0.0042],
         [ 0.0411,  0.2266, -0.3788,  ..., -0.1591, -0.1201, -0.1515],
         [-0.0753, -0.0920,  0.0401,  ..., -0.1883, -0.0638,  0.1088],
         ...,
         [-0.1585,  0.4778,  0.0478,  ...,  0.1142, -0.1948, -0.2410],
         [ 0.4990,  0.1309, -0.0756,  ...,  0.1941, -0.0396,  0.1294],
         [ 0.0233,  0.5075, -0.1227,  ...,  0.2180,  0.0169, -0.1456]],
        [[ 0.0006,  0.0469,  0.0403,  ...,  0.0100,  0.0158, -0.0043],
         [-0.0580, -0.0588, -0.3303,  ..., -0.1318, -0.0691,  0.0873],
         [-0.1027,  0.0327, -0.1646,  ...,  0.0510, -0.0181,  0.0287],
         ...,
         [ 0.2474,  0.1774,  0.0041,  ...,  0.1810, -0.0988,  0.0749],
         [ 0.0613,  0.4878,  0.0697,  ...,  0.2797, -0.0262, -0.0910],
         [ 0.0067,  0.0410,  0.0450,  ..., -0.0014,  0.0181,  0.0049]]],
       grad_fn=<NativeLayerNormBackward0>)
TRAIN G-HIDDEN IN_DEC :  tensor([[[ 0.0029,  0.0436,  0.0216,  ...,  0.0035,  0.0059,  0.0012],
         [-0.0320,  0.0604, -0.3925,  ..., -0.2646, -0.1134, -0.0595],
         [-0.0209, -0.3095,  0.0333,  ..., -0.1202, -0.0178, -0.0560],
         ...,
         [-0.0625,  0.3340,  0.2959,  ...,  0.0638,  0.0045, -0.3655],
         [ 0.2833, -0.1439,  0.0441,  ...,  0.2481, -0.1761,  0.1986],
         [-0.0381,  0.5991, -0.2123,  ...,  0.2404, -0.0276, -0.0811]],
        [[ 0.0055,  0.0421,  0.0276,  ...,  0.0034, -0.0191,  0.0107],
         [-0.0603, -0.0153, -0.3052,  ..., -0.1260, -0.0921,  0.0439],
         [-0.1280,  0.0216, -0.0023,  ...,  0.0502, -0.0573,  0.0488],
         ...,
         [-0.0104,  0.0429,  0.0210,  ...,  0.0051, -0.0151,  0.0129],
         [ 0.0026,  0.0500,  0.0089,  ...,  0.0074, -0.0138,  0.0064],
         [ 0.0074,  0.2792,  0.1425,  ...,  0.2609, -0.1506,  0.0061]]],
       grad_fn=<NativeLayerNormBackward0>)
---------------------------------------------------------------------
---------------------------------------------------------------------
TRAIN X-HIDDEN IN_DEC :  tensor([[[ 0.0029,  0.0466,  0.0241,  ...,  0.0040, -0.0009,  0.0042],
         [ 0.0411,  0.2266, -0.3788,  ..., -0.1591, -0.1201, -0.1515],
         [-0.0753, -0.0920,  0.0401,  ..., -0.1883, -0.0638,  0.1088],
         ...,
         [-0.1585,  0.4778,  0.0478,  ...,  0.1142, -0.1948, -0.2410],
         [ 0.4990,  0.1309, -0.0756,  ...,  0.1941, -0.0396,  0.1294],
         [ 0.0233,  0.5075, -0.1227,  ...,  0.2180,  0.0169, -0.1456]],
        [[ 0.0006,  0.0469,  0.0403,  ...,  0.0100,  0.0158, -0.0043],
         [-0.0580, -0.0588, -0.3303,  ..., -0.1318, -0.0691,  0.0873],
         [-0.1027,  0.0327, -0.1646,  ...,  0.0510, -0.0181,  0.0287],
         ...,
         [ 0.2474,  0.1774,  0.0041,  ...,  0.1810, -0.0988,  0.0749],
         [ 0.0613,  0.4878,  0.0697,  ...,  0.2797, -0.0262, -0.0910],
         [ 0.0067,  0.0410,  0.0450,  ..., -0.0014,  0.0181,  0.0049]]],
       grad_fn=<NativeLayerNormBackward0>)
TRAIN G-HIDDEN IN_DEC :  tensor([[[ 0.0029,  0.0436,  0.0216,  ...,  0.0035,  0.0059,  0.0012],
         [-0.0320,  0.0604, -0.3925,  ..., -0.2646, -0.1134, -0.0595],
         [-0.0209, -0.3095,  0.0333,  ..., -0.1202, -0.0178, -0.0560],
         ...,
         [-0.0625,  0.3340,  0.2959,  ...,  0.0638,  0.0045, -0.3655],
         [ 0.2833, -0.1439,  0.0441,  ...,  0.2481, -0.1761,  0.1986],
         [-0.0381,  0.5991, -0.2123,  ...,  0.2404, -0.0276, -0.0811]],
        [[ 0.0055,  0.0421,  0.0276,  ...,  0.0034, -0.0191,  0.0107],
         [-0.0603, -0.0153, -0.3052,  ..., -0.1260, -0.0921,  0.0439],
         [-0.1280,  0.0216, -0.0023,  ...,  0.0502, -0.0573,  0.0488],
         ...,
         [-0.0104,  0.0429,  0.0210,  ...,  0.0051, -0.0151,  0.0129],
         [ 0.0026,  0.0500,  0.0089,  ...,  0.0074, -0.0138,  0.0064],
         [ 0.0074,  0.2792,  0.1425,  ...,  0.2609, -0.1506,  0.0061]]],
       grad_fn=<NativeLayerNormBackward0>)
---------------------------------------------------------------------
---------------------------------------------------------------------
TRAIN X-HIDDEN IN_DEC :  tensor([[[ 0.0029,  0.0466,  0.0241,  ...,  0.0040, -0.0009,  0.0042],
         [ 0.0411,  0.2266, -0.3788,  ..., -0.1591, -0.1201, -0.1515],
         [-0.0753, -0.0920,  0.0401,  ..., -0.1883, -0.0638,  0.1088],
         ...,
         [-0.1585,  0.4778,  0.0478,  ...,  0.1142, -0.1948, -0.2410],
         [ 0.4990,  0.1309, -0.0756,  ...,  0.1941, -0.0396,  0.1294],
         [ 0.0233,  0.5075, -0.1227,  ...,  0.2180,  0.0169, -0.1456]],
        [[ 0.0006,  0.0469,  0.0403,  ...,  0.0100,  0.0158, -0.0043],
         [-0.0580, -0.0588, -0.3303,  ..., -0.1318, -0.0691,  0.0873],
         [-0.1027,  0.0327, -0.1646,  ...,  0.0510, -0.0181,  0.0287],
         ...,
         [ 0.2474,  0.1774,  0.0041,  ...,  0.1810, -0.0988,  0.0749],
         [ 0.0613,  0.4878,  0.0697,  ...,  0.2797, -0.0262, -0.0910],
         [ 0.0067,  0.0410,  0.0450,  ..., -0.0014,  0.0181,  0.0049]]],
       grad_fn=<NativeLayerNormBackward0>)
TRAIN G-HIDDEN IN_DEC :  tensor([[[ 0.0029,  0.0436,  0.0216,  ...,  0.0035,  0.0059,  0.0012],
         [-0.0320,  0.0604, -0.3925,  ..., -0.2646, -0.1134, -0.0595],
         [-0.0209, -0.3095,  0.0333,  ..., -0.1202, -0.0178, -0.0560],
         ...,
         [-0.0625,  0.3340,  0.2959,  ...,  0.0638,  0.0045, -0.3655],
         [ 0.2833, -0.1439,  0.0441,  ...,  0.2481, -0.1761,  0.1986],
         [-0.0381,  0.5991, -0.2123,  ...,  0.2404, -0.0276, -0.0811]],
        [[ 0.0055,  0.0421,  0.0276,  ...,  0.0034, -0.0191,  0.0107],
         [-0.0603, -0.0153, -0.3052,  ..., -0.1260, -0.0921,  0.0439],
         [-0.1280,  0.0216, -0.0023,  ...,  0.0502, -0.0573,  0.0488],
         ...,
         [-0.0104,  0.0429,  0.0210,  ...,  0.0051, -0.0151,  0.0129],
         [ 0.0026,  0.0500,  0.0089,  ...,  0.0074, -0.0138,  0.0064],
         [ 0.0074,  0.2792,  0.1425,  ...,  0.2609, -0.1506,  0.0061]]],
       grad_fn=<NativeLayerNormBackward0>)
---------------------------------------------------------------------
---------------------------------------------------------------------
TRAIN X-HIDDEN IN_DEC :  tensor([[[ 0.0029,  0.0466,  0.0241,  ...,  0.0040, -0.0009,  0.0042],
         [ 0.0411,  0.2266, -0.3788,  ..., -0.1591, -0.1201, -0.1515],
         [-0.0753, -0.0920,  0.0401,  ..., -0.1883, -0.0638,  0.1088],
         ...,
         [-0.1585,  0.4778,  0.0478,  ...,  0.1142, -0.1948, -0.2410],
         [ 0.4990,  0.1309, -0.0756,  ...,  0.1941, -0.0396,  0.1294],
         [ 0.0233,  0.5075, -0.1227,  ...,  0.2180,  0.0169, -0.1456]],
        [[ 0.0006,  0.0469,  0.0403,  ...,  0.0100,  0.0158, -0.0043],
         [-0.0580, -0.0588, -0.3303,  ..., -0.1318, -0.0691,  0.0873],
         [-0.1027,  0.0327, -0.1646,  ...,  0.0510, -0.0181,  0.0287],
         ...,
         [ 0.2474,  0.1774,  0.0041,  ...,  0.1810, -0.0988,  0.0749],
         [ 0.0613,  0.4878,  0.0697,  ...,  0.2797, -0.0262, -0.0910],
         [ 0.0067,  0.0410,  0.0450,  ..., -0.0014,  0.0181,  0.0049]]],
       grad_fn=<NativeLayerNormBackward0>)
TRAIN G-HIDDEN IN_DEC :  tensor([[[ 0.0029,  0.0436,  0.0216,  ...,  0.0035,  0.0059,  0.0012],
         [-0.0320,  0.0604, -0.3925,  ..., -0.2646, -0.1134, -0.0595],
         [-0.0209, -0.3095,  0.0333,  ..., -0.1202, -0.0178, -0.0560],
         ...,
         [-0.0625,  0.3340,  0.2959,  ...,  0.0638,  0.0045, -0.3655],
         [ 0.2833, -0.1439,  0.0441,  ...,  0.2481, -0.1761,  0.1986],
         [-0.0381,  0.5991, -0.2123,  ...,  0.2404, -0.0276, -0.0811]],
        [[ 0.0055,  0.0421,  0.0276,  ...,  0.0034, -0.0191,  0.0107],
         [-0.0603, -0.0153, -0.3052,  ..., -0.1260, -0.0921,  0.0439],
         [-0.1280,  0.0216, -0.0023,  ...,  0.0502, -0.0573,  0.0488],
         ...,
         [-0.0104,  0.0429,  0.0210,  ...,  0.0051, -0.0151,  0.0129],
         [ 0.0026,  0.0500,  0.0089,  ...,  0.0074, -0.0138,  0.0064],
         [ 0.0074,  0.2792,  0.1425,  ...,  0.2609, -0.1506,  0.0061]]],
       grad_fn=<NativeLayerNormBackward0>)
---------------------------------------------------------------------
---------------------------------------------------------------------
TRAIN X-HIDDEN IN_DEC :  tensor([[[ 0.0029,  0.0466,  0.0241,  ...,  0.0040, -0.0009,  0.0042],
         [ 0.0411,  0.2266, -0.3788,  ..., -0.1591, -0.1201, -0.1515],
         [-0.0753, -0.0920,  0.0401,  ..., -0.1883, -0.0638,  0.1088],
         ...,
         [-0.1585,  0.4778,  0.0478,  ...,  0.1142, -0.1948, -0.2410],
         [ 0.4990,  0.1309, -0.0756,  ...,  0.1941, -0.0396,  0.1294],
         [ 0.0233,  0.5075, -0.1227,  ...,  0.2180,  0.0169, -0.1456]],
        [[ 0.0006,  0.0469,  0.0403,  ...,  0.0100,  0.0158, -0.0043],
         [-0.0580, -0.0588, -0.3303,  ..., -0.1318, -0.0691,  0.0873],
         [-0.1027,  0.0327, -0.1646,  ...,  0.0510, -0.0181,  0.0287],
         ...,
         [ 0.2474,  0.1774,  0.0041,  ...,  0.1810, -0.0988,  0.0749],
         [ 0.0613,  0.4878,  0.0697,  ...,  0.2797, -0.0262, -0.0910],
         [ 0.0067,  0.0410,  0.0450,  ..., -0.0014,  0.0181,  0.0049]]],
       grad_fn=<NativeLayerNormBackward0>)
TRAIN G-HIDDEN IN_DEC :  tensor([[[ 0.0029,  0.0436,  0.0216,  ...,  0.0035,  0.0059,  0.0012],
         [-0.0320,  0.0604, -0.3925,  ..., -0.2646, -0.1134, -0.0595],
         [-0.0209, -0.3095,  0.0333,  ..., -0.1202, -0.0178, -0.0560],
         ...,
         [-0.0625,  0.3340,  0.2959,  ...,  0.0638,  0.0045, -0.3655],
         [ 0.2833, -0.1439,  0.0441,  ...,  0.2481, -0.1761,  0.1986],
         [-0.0381,  0.5991, -0.2123,  ...,  0.2404, -0.0276, -0.0811]],
        [[ 0.0055,  0.0421,  0.0276,  ...,  0.0034, -0.0191,  0.0107],
         [-0.0603, -0.0153, -0.3052,  ..., -0.1260, -0.0921,  0.0439],
         [-0.1280,  0.0216, -0.0023,  ...,  0.0502, -0.0573,  0.0488],
         ...,
         [-0.0104,  0.0429,  0.0210,  ...,  0.0051, -0.0151,  0.0129],
         [ 0.0026,  0.0500,  0.0089,  ...,  0.0074, -0.0138,  0.0064],
         [ 0.0074,  0.2792,  0.1425,  ...,  0.2609, -0.1506,  0.0061]]],
       grad_fn=<NativeLayerNormBackward0>)
---------------------------------------------------------------------
---------------------------------------------------------------------
TRAIN X-HIDDEN IN_DEC :  tensor([[[ 0.0029,  0.0466,  0.0241,  ...,  0.0040, -0.0009,  0.0042],
         [ 0.0411,  0.2266, -0.3788,  ..., -0.1591, -0.1201, -0.1515],
         [-0.0753, -0.0920,  0.0401,  ..., -0.1883, -0.0638,  0.1088],
         ...,
         [-0.1585,  0.4778,  0.0478,  ...,  0.1142, -0.1948, -0.2410],
         [ 0.4990,  0.1309, -0.0756,  ...,  0.1941, -0.0396,  0.1294],
         [ 0.0233,  0.5075, -0.1227,  ...,  0.2180,  0.0169, -0.1456]],
        [[ 0.0006,  0.0469,  0.0403,  ...,  0.0100,  0.0158, -0.0043],
         [-0.0580, -0.0588, -0.3303,  ..., -0.1318, -0.0691,  0.0873],
         [-0.1027,  0.0327, -0.1646,  ...,  0.0510, -0.0181,  0.0287],
         ...,
         [ 0.2474,  0.1774,  0.0041,  ...,  0.1810, -0.0988,  0.0749],
         [ 0.0613,  0.4878,  0.0697,  ...,  0.2797, -0.0262, -0.0910],
         [ 0.0067,  0.0410,  0.0450,  ..., -0.0014,  0.0181,  0.0049]]],
       grad_fn=<NativeLayerNormBackward0>)
TRAIN G-HIDDEN IN_DEC :  tensor([[[ 0.0029,  0.0436,  0.0216,  ...,  0.0035,  0.0059,  0.0012],
         [-0.0320,  0.0604, -0.3925,  ..., -0.2646, -0.1134, -0.0595],
         [-0.0209, -0.3095,  0.0333,  ..., -0.1202, -0.0178, -0.0560],
         ...,
         [-0.0625,  0.3340,  0.2959,  ...,  0.0638,  0.0045, -0.3655],
         [ 0.2833, -0.1439,  0.0441,  ...,  0.2481, -0.1761,  0.1986],
         [-0.0381,  0.5991, -0.2123,  ...,  0.2404, -0.0276, -0.0811]],
        [[ 0.0055,  0.0421,  0.0276,  ...,  0.0034, -0.0191,  0.0107],
         [-0.0603, -0.0153, -0.3052,  ..., -0.1260, -0.0921,  0.0439],
         [-0.1280,  0.0216, -0.0023,  ...,  0.0502, -0.0573,  0.0488],
         ...,
         [-0.0104,  0.0429,  0.0210,  ...,  0.0051, -0.0151,  0.0129],
         [ 0.0026,  0.0500,  0.0089,  ...,  0.0074, -0.0138,  0.0064],
         [ 0.0074,  0.2792,  0.1425,  ...,  0.2609, -0.1506,  0.0061]]],
       grad_fn=<NativeLayerNormBackward0>)
---------------------------------------------------------------------
---------------------------------------------------------------------
TRAIN X-HIDDEN IN_DEC :  tensor([[[ 0.0029,  0.0466,  0.0241,  ...,  0.0040, -0.0009,  0.0042],
         [ 0.0411,  0.2266, -0.3788,  ..., -0.1591, -0.1201, -0.1515],
         [-0.0753, -0.0920,  0.0401,  ..., -0.1883, -0.0638,  0.1088],
         ...,
         [-0.1585,  0.4778,  0.0478,  ...,  0.1142, -0.1948, -0.2410],
         [ 0.4990,  0.1309, -0.0756,  ...,  0.1941, -0.0396,  0.1294],
         [ 0.0233,  0.5075, -0.1227,  ...,  0.2180,  0.0169, -0.1456]],
        [[ 0.0006,  0.0469,  0.0403,  ...,  0.0100,  0.0158, -0.0043],
         [-0.0580, -0.0588, -0.3303,  ..., -0.1318, -0.0691,  0.0873],
         [-0.1027,  0.0327, -0.1646,  ...,  0.0510, -0.0181,  0.0287],
         ...,
         [ 0.2474,  0.1774,  0.0041,  ...,  0.1810, -0.0988,  0.0749],
         [ 0.0613,  0.4878,  0.0697,  ...,  0.2797, -0.0262, -0.0910],
         [ 0.0067,  0.0410,  0.0450,  ..., -0.0014,  0.0181,  0.0049]]],
       grad_fn=<NativeLayerNormBackward0>)
TRAIN G-HIDDEN IN_DEC :  tensor([[[ 0.0029,  0.0436,  0.0216,  ...,  0.0035,  0.0059,  0.0012],
         [-0.0320,  0.0604, -0.3925,  ..., -0.2646, -0.1134, -0.0595],
         [-0.0209, -0.3095,  0.0333,  ..., -0.1202, -0.0178, -0.0560],
         ...,
         [-0.0625,  0.3340,  0.2959,  ...,  0.0638,  0.0045, -0.3655],
         [ 0.2833, -0.1439,  0.0441,  ...,  0.2481, -0.1761,  0.1986],
         [-0.0381,  0.5991, -0.2123,  ...,  0.2404, -0.0276, -0.0811]],
        [[ 0.0055,  0.0421,  0.0276,  ...,  0.0034, -0.0191,  0.0107],
         [-0.0603, -0.0153, -0.3052,  ..., -0.1260, -0.0921,  0.0439],
         [-0.1280,  0.0216, -0.0023,  ...,  0.0502, -0.0573,  0.0488],
         ...,
         [-0.0104,  0.0429,  0.0210,  ...,  0.0051, -0.0151,  0.0129],
         [ 0.0026,  0.0500,  0.0089,  ...,  0.0074, -0.0138,  0.0064],
         [ 0.0074,  0.2792,  0.1425,  ...,  0.2609, -0.1506,  0.0061]]],
       grad_fn=<NativeLayerNormBackward0>)
---------------------------------------------------------------------
-------------------------------------------------------------
OUTPUT DECOD :  tensor([[[-0.0700, -0.0440, -0.2466,  ...,  0.3994,  0.1853,  0.2262],
         [ 0.1382, -0.1380, -0.2521,  ...,  0.1668,  0.2160,  0.2153],
         [ 0.2548, -0.2809, -0.1634,  ...,  0.3758,  0.2851,  0.4812],
         ...,
         [ 0.4539,  1.3493, -2.8211,  ...,  2.4662,  1.5538, -0.6924],
         [ 0.0603, -0.7730, -1.2963,  ...,  1.5540,  0.8339,  0.3876],
         [ 0.5564,  1.1079, -0.3083,  ..., -0.8612,  0.6976,  0.0992]],
        [[ 0.3575, -0.0692, -0.0965,  ...,  0.0912,  0.1449, -0.0756],
         [ 0.4341, -0.0780, -0.2618,  ...,  0.0491,  0.2176,  0.3627],
         [-0.0528, -0.0145, -0.2431,  ...,  0.0630,  0.0832, -0.0942],
         ...,
         [-0.0277, -0.2948, -0.1485,  ...,  0.0530,  0.2506, -0.0852],
         [ 0.7420, -0.1355, -0.9793,  ...,  1.0092,  0.6201,  0.4226],
         [ 0.1715, -0.4572, -0.9932,  ..., -0.3305,  0.9733,  0.1733]]],
       grad_fn=<NativeLayerNormBackward0>)
-------------------------------------------------------------
-------------------------------------------------------------
LM LOGITS :  tensor([[[ 1.1485e+01, -1.2865e+00,  7.5362e+00,  ..., -1.1697e+00,
          -1.2629e+00,  4.7968e+00],
         [-3.1987e+00, -1.4080e+00,  6.0023e+00,  ..., -2.9566e-01,
          -4.8436e-01,  4.2869e+00],
         [ 1.1881e+01, -1.2930e+00,  6.9203e+00,  ..., -1.5221e+00,
          -1.4441e+00,  4.2573e+00],
         ...,
         [-6.1801e+01, -3.4893e+00,  5.9278e+00,  ..., -1.2349e+00,
          -1.4018e-02,  7.5908e+00],
         [-4.4094e+00, -2.7600e+00,  8.8418e+00,  ..., -1.5271e+00,
          -1.8502e+00,  6.2919e+00],
         [-4.9138e+01, -3.3884e+00,  6.7343e+00,  ..., -1.3970e-01,
           6.9538e-01,  9.2635e+00]],
        [[ 1.2912e+01, -1.3750e+00,  6.1995e+00,  ..., -1.2741e+00,
          -9.5859e-01,  3.0710e+00],
         [-3.2304e+00, -1.2871e+00,  4.6462e+00,  ..., -5.8918e-01,
          -1.2474e-01,  2.1812e+00],
         [ 7.3788e+00, -1.7234e+00,  5.2332e+00,  ..., -1.0686e+00,
          -1.2208e+00,  2.7269e+00],
         ...,
         [-1.0230e+01, -1.8179e+00,  5.0861e+00,  ..., -1.2269e+00,
          -1.1400e+00,  2.0596e+00],
         [-1.3736e+01, -3.0816e+00,  7.7103e+00,  ..., -2.4234e+00,
          -2.3742e+00,  1.1102e+00],
         [-3.1508e+01, -2.5314e+00,  4.2819e+00,  ..., -8.0198e-01,
          -7.4033e-01,  4.2990e+00]]], grad_fn=<AddBackward0>)
-------------------------------------------------------------
-------------------------------------------------------------
TOKEN :  tensor([[ 11.4850,  -1.2865,   7.5362,  ...,  -1.1697,  -1.2629,   4.7968],
        [ -3.1987,  -1.4080,   6.0023,  ...,  -0.2957,  -0.4844,   4.2869],
        [ 11.8813,  -1.2930,   6.9203,  ...,  -1.5221,  -1.4441,   4.2573],
        ...,
        [-10.2304,  -1.8179,   5.0861,  ...,  -1.2269,  -1.1400,   2.0596],
        [-13.7364,  -3.0816,   7.7103,  ...,  -2.4234,  -2.3742,   1.1102],
        [-31.5081,  -2.5314,   4.2819,  ...,  -0.8020,  -0.7403,   4.2990]],
       grad_fn=<ViewBackward0>)
